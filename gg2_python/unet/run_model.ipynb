{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os, glob\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pydicom\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "from dataset import CTDataset\n",
        "#from logger import Logger\n",
        "from loss import DiceLoss\n",
        "from unet import UNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from collections import OrderedDict\n",
        "\n",
        "from train import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Haimo Dong\\Desktop\\gg2_python\n",
            "c:\\Users\\Haimo Dong\\Desktop\\gg2_python\\unet\\model\\epoch200_test_model.pth\n",
            "(128, 128)\n",
            "(1, 128, 128)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "roots = os.path.split(os.getcwd())\n",
        "root = roots[0]\n",
        "model_path = os.path.join(root, 'unet\\\\model\\\\epoch200_test_model.pth')\n",
        "mask_folder_path = os.path.join(root, 'data\\\\train\\\\mask')\n",
        "image_folder_path = os.path.join(root, 'data\\\\train\\\\image')\n",
        "pred_folder_path = os.path.join(root, 'data\\\\prediction')\n",
        "\n",
        "print(root)\n",
        "print(model_path)\n",
        "\n",
        "test_path = os.path.join(root, 'data\\\\train\\\\mask\\\\z_mask045.txt')\n",
        "xxx = np.loadtxt(test_path)\n",
        "#plt.imshow(xxx)\n",
        "print(xxx.shape)\n",
        "y = np.expand_dims(xxx, axis=0)\n",
        "print(y.shape)\n",
        "plt.imshow(y[0])\n",
        "mask_folder_path = os.path.join(root, 'data\\\\train\\\\mask')\n",
        "image_folder_path = os.path.join(root, 'data\\\\train\\\\image')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "UNet(\n",
              "  (encoder1): Sequential(\n",
              "    (enc1conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (enc1norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (enc1relu1): ReLU(inplace=True)\n",
              "    (enc1conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (enc1norm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (enc1relu2): ReLU(inplace=True)\n",
              "  )\n",
              "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (encoder2): Sequential(\n",
              "    (enc2conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (enc2norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (enc2relu1): ReLU(inplace=True)\n",
              "    (enc2conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (enc2norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (enc2relu2): ReLU(inplace=True)\n",
              "  )\n",
              "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (encoder3): Sequential(\n",
              "    (enc3conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (enc3norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (enc3relu1): ReLU(inplace=True)\n",
              "    (enc3conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (enc3norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (enc3relu2): ReLU(inplace=True)\n",
              "  )\n",
              "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (encoder4): Sequential(\n",
              "    (enc4conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (enc4norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (enc4relu1): ReLU(inplace=True)\n",
              "    (enc4conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (enc4norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (enc4relu2): ReLU(inplace=True)\n",
              "  )\n",
              "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (bottleneck): Sequential(\n",
              "    (bottleneckconv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bottlenecknorm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bottleneckrelu1): ReLU(inplace=True)\n",
              "    (bottleneckconv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bottlenecknorm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bottleneckrelu2): ReLU(inplace=True)\n",
              "  )\n",
              "  (upconv4): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (decoder4): Sequential(\n",
              "    (dec4conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (dec4norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (dec4relu1): ReLU(inplace=True)\n",
              "    (dec4conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (dec4norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (dec4relu2): ReLU(inplace=True)\n",
              "  )\n",
              "  (upconv3): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (decoder3): Sequential(\n",
              "    (dec3conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (dec3norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (dec3relu1): ReLU(inplace=True)\n",
              "    (dec3conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (dec3norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (dec3relu2): ReLU(inplace=True)\n",
              "  )\n",
              "  (upconv2): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (decoder2): Sequential(\n",
              "    (dec2conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (dec2norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (dec2relu1): ReLU(inplace=True)\n",
              "    (dec2conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (dec2norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (dec2relu2): ReLU(inplace=True)\n",
              "  )\n",
              "  (upconv1): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (decoder1): Sequential(\n",
              "    (dec1conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (dec1norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (dec1relu1): ReLU(inplace=True)\n",
              "    (dec1conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (dec1norm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (dec1relu2): ReLU(inplace=True)\n",
              "  )\n",
              "  (conv): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              ")"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = torch.load(model_path)\n",
        "model.eval()\n",
        "device = torch.device(\"cpu\" if not torch.cuda.is_available() else 'cuda')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "CT_dataset = CTDataset(image_folder_path, mask_folder_path)\n",
        "\n",
        "loader_train, loader_valid = data_loaders(CT_dataset, CT_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nfor i, data in enumerate(loader_train):\\n\\n    x, y_true = data\\n    x, y_true = x.to(device), y_true.to(device)\\n    y_pred = model(x)\\n    batch_size = x.shape[0]\\n    print(x.shape)\\n    \\n    for j in range(batch_size):\\n        image, mask, pred_mask = x[j][0].cpu().detach().numpy(), y_true[j][0].cpu().detach().numpy(), y_pred[j][0].cpu().detach().numpy(), \\n        \\n        plt.figure(figsize=(15, 15))\\n    \\n        # plot 3 orthogonal slices\\n        a1 = plt.subplot(2, 2, 1)\\n        plt.imshow(image)\\n    \\n\\n        a2 = plt.subplot(2, 2, 2)\\n        plt.imshow(mask)\\n\\n\\n        a3 = plt.subplot(2, 2, 3)\\n        plt.imshow(pred_mask)\\n\\n        \\n        plt.show()\\n    #print(x[0].shape, y_true.shape, y_pred.shape\\n    '"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "for i, data in enumerate(loader_train):\n",
        "\n",
        "    x, y_true = data\n",
        "    x, y_true = x.to(device), y_true.to(device)\n",
        "    y_pred = model(x)\n",
        "    batch_size = x.shape[0]\n",
        "    print(x.shape)\n",
        "    \n",
        "    for j in range(batch_size):\n",
        "        image, mask, pred_mask = x[j][0].cpu().detach().numpy(), y_true[j][0].cpu().detach().numpy(), y_pred[j][0].cpu().detach().numpy(), \n",
        "        \n",
        "        plt.figure(figsize=(15, 15))\n",
        "    \n",
        "        # plot 3 orthogonal slices\n",
        "        a1 = plt.subplot(2, 2, 1)\n",
        "        plt.imshow(image)\n",
        "    \n",
        "\n",
        "        a2 = plt.subplot(2, 2, 2)\n",
        "        plt.imshow(mask)\n",
        "\n",
        "\n",
        "        a3 = plt.subplot(2, 2, 3)\n",
        "        plt.imshow(pred_mask)\n",
        "\n",
        "        \n",
        "        plt.show()\n",
        "    #print(x[0].shape, y_true.shape, y_pred.shape\n",
        "    '''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred_mask3d = []\n",
        "\n",
        "for image_name in os.listdir(image_folder_path):\n",
        "    image_path = os.path.join(image_folder_path, image_name)\n",
        "    image = np.loadtxt(image_path)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    image = torch.tensor(np.expand_dims(image, axis=0), dtype=torch.float32)\n",
        "    image = image.to(device)\n",
        "    \n",
        "    mask_pred = model(image)\n",
        "    mask_pred = mask_pred.cpu().detach().numpy()[0][0]\n",
        "\n",
        "    pred_mask3d.append(mask_pred)\n",
        "    save_path = os.path.join(pred_folder_path, 'pred_' + image_name)\n",
        "    np.savetxt(save_path, mask_pred)\n",
        "    #plt.imshow(mask_pred)\n",
        "\n",
        "pred_mask3d = np.array(pred_mask3d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "from skimage.measure import marching_cubes_lewiner\n",
        "import meshplot as mp\n",
        "from stl import mesh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\HAIMOD~1\\AppData\\Local\\Temp/ipykernel_6176/1897982135.py:1: FutureWarning: marching_cubes_lewiner is deprecated in favor of marching_cubes. marching_cubes_lewiner will be removed in version 0.19\n",
            "  vertices,faces,_,_ = marching_cubes_lewiner(mask3d)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92bcfac14c4f431f97ca54ce251bcc6c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(36.5, 50.…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "vertices,faces,_,_ = marching_cubes_lewiner(pred_mask3d)\n",
        "mp.plot(vertices, faces, return_plot=False)\n",
        "\n",
        "def dataToMesh(vert, faces):\n",
        "    mm = mesh.Mesh(np.zeros(faces.shape[0], dtype=mesh.Mesh.dtype))\n",
        "    for i, f in enumerate(faces):\n",
        "        for j in range(3):\n",
        "            mm.vectors[i][j] = vert[f[j],:]\n",
        "    return mm\n",
        "\n",
        "mm = dataToMesh(vertices, faces)\n",
        "mm.save('test_a_scan.stl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "d7288e82646d3164eca24130947288f8779d11454649f2c02a5dfc42af7f324c"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
